{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Skill Extraction Pipelines: LLM-only vs. LLM + Knowledge Graph (ESCO)\n",
        "Domain: Data Science\n",
        "This notebook implements and compares two pipelines for extracting professional skills from resumes using Large Language Models (LLMs), specifically in the Civil Engineering domain.\n",
        "\n",
        "1. LLM-only Pipeline\n",
        "The LLM-only pipeline uses an instruction-following LLM (LLaMA 3.3–70B via Hugging Face/SambaNova) to extract skills from unstructured resume text. Prompts are designed using a zero-shot format, where the model is asked to identify comma-separated skills without additional examples or context.\n",
        "\n",
        "Key Features:\n",
        "\n",
        "Zero-shot prompting only.\n",
        "\n",
        "No external knowledge injection.\n",
        "\n",
        "Evaluated on the Data Science category.\n",
        "\n",
        "Output is post-processed and mapped to ESCO concepts using string matching for evaluation.\n",
        "\n",
        "2.  LLM + Knowledge Graph (ESCO-Guided) Pipeline\n",
        "The LLM+KG pipeline augments the same LLM with structured guidance from the ESCO ontology. Domain-specific ESCO occupations and skills are integrated into the prompt to provide richer semantic cues.\n",
        "\n",
        "Key Features:\n",
        "\n",
        "Combines few-shot prompting with ESCO keyword injection.\n",
        "\n",
        "Provides context-aware skill extraction with improved semantic precision.\n",
        "\n",
        "Targets improved recall, precision, and standardization of outputs.\n",
        "\n",
        "Evaluated using the same mapping and metrics as the LLM-only pipeline for fair comparison.\n",
        "\n",
        "Objective:\n",
        "\n",
        "To evaluate whether lightweight prompt-based knowledge graph integration improves LLM skill extraction performance—without requiring any model fine-tuning.\n",
        "\n",
        "Evaluation Metrics:\n",
        "\n",
        "For both pipelines:\n",
        "\n",
        "Extracted skills are mapped to ESCO concepts using exact and fuzzy string matching.\n",
        "\n",
        "Performance is evaluated using precision, recall, and F1-score against ESCO-aligned ground truth skills."
      ],
      "metadata": {
        "id": "htqXbnYO3dNY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6w9lL5uMSKb"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install -q huggingface_hub datasets tqdm\n",
        "!pip install fuzzywuzzy\n",
        "!pip install python-Levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wtWfu-QB_bp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import re\n",
        "import time\n",
        "import os\n",
        "from huggingface_hub import InferenceClient\n",
        "from tqdm.auto import tqdm\n",
        "from fuzzywuzzy import process\n",
        "from fuzzywuzzy import fuzz\n",
        "import ast\n",
        "from google.colab import userdata\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0mohZRsRwMJ"
      },
      "source": [
        "### Data Loading and Initial Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfml-1LsXTUY"
      },
      "outputs": [],
      "source": [
        "resumeatlas_path = \"resumeAtlas.csv\"\n",
        "df = pd.read_csv(resumeatlas_path)\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3SY6LAlYMRG"
      },
      "outputs": [],
      "source": [
        "df[\"Text_Clean\"] = df[\"Text\"].str.lower()\n",
        "df[\"Text_Clean\"] = df[\"Text_Clean\"].str.replace(r'\\d+', ' ', regex=True)\n",
        "df[\"Text_Clean\"] = df[\"Text_Clean\"].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "df[\"Text_Clean\"] = df[\"Text_Clean\"].str.replace(r'\\s+', ' ', regex=True)\n",
        "df[\"Text_Clean\"] = df[\"Text_Clean\"].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25d9GzfeYTod"
      },
      "outputs": [],
      "source": [
        "# Create clean column with lowercase\n",
        "df[\"Text_Clean\"] = df[\"Text\"].str.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maVdRb_PYaVx"
      },
      "outputs": [],
      "source": [
        "# Remove numbers/dates - simplified approach\n",
        "df[\"Text_Clean\"] = df[\"Text_Clean\"].str.replace(r'\\d+', ' ', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdwjrJYwYhkf"
      },
      "outputs": [],
      "source": [
        "# Remove special chars and normalize spaces\n",
        "df[\"Text_Clean\"] = df[\"Text_Clean\"].str.replace(r'[^\\w\\s]', ' ', regex=True)\n",
        "df[\"Text_Clean\"] = df[\"Text_Clean\"].str.replace(r'\\s+', ' ', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HQ-ZY8xZy8N"
      },
      "outputs": [],
      "source": [
        "# Final cleanup\n",
        "df[\"Text_Clean\"] = df[\"Text_Clean\"].str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_08R_v7eQq1"
      },
      "outputs": [],
      "source": [
        "print(\"Original:\\n\", repr(df.loc[0, \"Text\"]))\n",
        "print(\"\\nCleaned:\\n\", repr(df.loc[0, \"Text_Clean\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwyXql29aH-E"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"resumeAtlas_cleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiG3qhEaEXFL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"resumeAtlas_cleaned.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3T5G6sESKX_"
      },
      "source": [
        "### Cleaning and Extracting ( LLM only )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltdK575urP6T"
      },
      "outputs": [],
      "source": [
        "#  Initial Setup: Hugging Face Token and InferenceClient\n",
        "HF_TOKEN = userdata.get('HF_TOKEN_L')\n",
        "client = InferenceClient(\n",
        "    provider=\"sambanova\",\n",
        "    api_key=HF_TOKEN,\n",
        ")\n",
        "\n",
        "#  Load Input Resumes\n",
        "df = pd.read_csv(\"resumeAtlas_cleaned.csv\")\n",
        "df_resumes_for_extraction = df[df['Category'] == 'Data Science'].copy()\n",
        "\n",
        "RESUME_TEXT_COLUMN = \"Text_Clean\"\n",
        "\n",
        "def clean_output(text):\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return \"\"\n",
        "\n",
        "# Convert to lowercase and split by common delimiters\n",
        "    skills_list = [s.strip().lower() for s in re.split(r\"[\\s,;]+\", text) if s.strip()]\n",
        "    return \", \".join(skills_list)\n",
        "\n",
        "# Define the Adapted Skill Extraction Function using InferenceClient\n",
        "LLAMA_MODEL_ID = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
        "\n",
        "def extract_skills_llama3_sambanova(resume_text):\n",
        "    MAX_RESUME_CHARS_FOR_LLM = 4000\n",
        "    if len(resume_text) > MAX_RESUME_CHARS_FOR_LLM:\n",
        "        resume_text_for_llm = resume_text[:MAX_RESUME_CHARS_FOR_LLM] + \"...\"\n",
        "    else:\n",
        "        resume_text_for_llm = resume_text\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a professional resume parser. Extract all technical skills from the resume below. Only output a clean, comma-separated list. No extra words.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"{resume_text_for_llm}\\n\\nSkills:\"}\n",
        "    ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=LLAMA_MODEL_ID,\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "        max_tokens=200,\n",
        "    )\n",
        "    raw_output = completion.choices[0].message.content\n",
        "    return raw_output\n",
        "\n",
        "# Apply the Skill Extraction Function\n",
        "tqdm.pandas(desc=f\"Extracting Skills ({LLAMA_MODEL_ID} via SambaNova)\")\n",
        "df_resumes_for_extraction[\"extracted_skills_raw\"] = df_resumes_for_extraction[RESUME_TEXT_COLUMN].progress_apply(extract_skills_llama3_sambanova)\n",
        "\n",
        "output_path = \"extracted_skills_output.csv\"\n",
        "df_resumes_for_extraction.to_csv(output_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSbvdBcnrQ4Z"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"extracted_skills_output.csv\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBEUjvkoSkMg"
      },
      "source": [
        "### Mapping skills to ESCO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tC0mvY4fL4P"
      },
      "outputs": [],
      "source": [
        "df_mapping = pd.read_csv(\"extracted_skills_output.csv\")\n",
        "esco_df = pd.read_csv(\"skills_en.csv\")[['preferredLabel', 'altLabels']].copy()\n",
        "\n",
        "# Clean LLM Output Function\n",
        "def clean_extracted_skills(text):\n",
        "    \"\"\"Cleans raw LLM text output into a set of normalized skill phrases.\"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return set()\n",
        "\n",
        "    text = text.lower().replace(';', ',').replace(' and ', ', ')\n",
        "    raw_skill_candidates = re.split(r',\\s*|\\s*,\\s*', text)\n",
        "\n",
        "    return {\n",
        "        re.sub(r'[^a-z0-9\\s\\.\\+#-]+', '', s).strip()\n",
        "        for s in raw_skill_candidates\n",
        "        if s.strip() and len(s.strip()) > 1 and not s.strip().isdigit()\n",
        "    }\n",
        "\n",
        "# Apply cleaning\n",
        "df_mapping['extracted_skills_set'] = df_mapping['extracted_skills_raw'].apply(clean_extracted_skills)\n",
        "\n",
        "# Preprocess ESCO data for faster lookups\n",
        "esco_preferred_lower_list = esco_df['preferredLabel'].str.lower().tolist()\n",
        "pref_map = {label.lower(): label for label in esco_df['preferredLabel'].unique()}\n",
        "\n",
        "alt_map = {\n",
        "    alt.strip(): row['preferredLabel']\n",
        "    for _, row in esco_df.iterrows()\n",
        "    if isinstance(row['altLabels'], str)\n",
        "    for alt in row['altLabels'].lower().replace('\"', '').split('|')\n",
        "    if alt.strip()\n",
        "}\n",
        "\n",
        "# ESCO Mapping Function\n",
        "def map_to_esco(skill_name, pref_map_ref, alt_map_ref, esco_lower_list_ref):\n",
        "    \"\"\"Maps an extracted skill to an ESCO preferredLabel using exact/fuzzy matching.\"\"\"\n",
        "    skill = str(skill_name).lower().strip()\n",
        "    if not skill:\n",
        "        return None\n",
        "\n",
        "    # Exact match (preferred or alternative)\n",
        "    if skill in pref_map_ref: return pref_map_ref[skill]\n",
        "    if skill in alt_map_ref: return alt_map_ref[skill]\n",
        "\n",
        "    # Fuzzy match\n",
        "    fuzzy_match_result = process.extractOne(skill, esco_lower_list_ref, scorer=fuzz.token_set_ratio)\n",
        "    if fuzzy_match_result and fuzzy_match_result[1] >= 60: # score >= 60\n",
        "        original_label_row = esco_df[esco_df['preferredLabel'].str.lower() == fuzzy_match_result[0]]\n",
        "        if not original_label_row.empty:\n",
        "            return original_label_row['preferredLabel'].iloc[0]\n",
        "    return None\n",
        "\n",
        "# Apply ESCO Mapping\n",
        "df_mapping[\"mapped_skills_str\"] = df_mapping['extracted_skills_set'].progress_apply(\n",
        "    lambda s: \", \".join(sorted(list(filter(None, [map_to_esco(x, pref_map, alt_map, esco_preferred_lower_list) for x in s]))))\n",
        ")\n",
        "\n",
        "output_path = \"mapped_skills_output.csv\"\n",
        "\n",
        "columns_to_save = [\n",
        "    'Unnamed: 0', 'Category', 'Text_Clean', 'extracted_skills_raw',\n",
        "    'original_extracted_skills_for_eval', 'mapped_skills_str'\n",
        "]\n",
        "df_mapping['original_extracted_skills_for_eval'] = df_mapping['extracted_skills_set'].apply(lambda s: str(list(s)))\n",
        "\n",
        "existing_columns_to_save = [col for col in columns_to_save if col in df_mapping.columns]\n",
        "\n",
        "df_mapping[existing_columns_to_save].to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Mapped skills saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQfOtZtTi1CH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"mapped_skills_output.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHgco1v73mHi"
      },
      "source": [
        "### ESCO Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LS8vaZRUFiC"
      },
      "outputs": [],
      "source": [
        "# Load ESCO datasets\n",
        "occupations = pd.read_csv('occupations_en.csv')\n",
        "occ_skill_rels = pd.read_csv('occupationSkillRelations_en.csv')\n",
        "skills = pd.read_csv('skills_en.csv')\n",
        "\n",
        "# Prepare job data\n",
        "jobs = pd.DataFrame({\n",
        "    'job_id': [1],\n",
        "    'category': ['Data Scientist'],\n",
        "    'other_info': ['...']\n",
        "})\n",
        "\n",
        "# Map to ESCO occupations\n",
        "jobs['norm_category'] = jobs['category'].str.lower().str.strip()\n",
        "occupations['norm_label'] = occupations['preferredLabel'].str.lower().str.strip()\n",
        "\n",
        "# Merge jobs with ESCO occupations and skills\n",
        "esco_skills = (\n",
        "    jobs.merge(\n",
        "        occupations[['conceptUri', 'preferredLabel', 'norm_label']],\n",
        "        left_on='norm_category',\n",
        "        right_on='norm_label',\n",
        "        how='left'\n",
        "    )\n",
        "    .merge(\n",
        "        occ_skill_rels,\n",
        "        left_on='conceptUri',\n",
        "        right_on='occupationUri',\n",
        "        how='left'\n",
        "    )\n",
        "    .merge(\n",
        "        skills[['conceptUri', 'preferredLabel']],\n",
        "        left_on='skillUri',\n",
        "        right_on='conceptUri',\n",
        "        how='left'\n",
        "    )\n",
        ")\n",
        "\n",
        "# Aggregate expected skills\n",
        "expected_skills = (\n",
        "    esco_skills.dropna(subset=['preferredLabel_y'])\n",
        "    .groupby(['job_id', 'category'], as_index=False)\n",
        "    ['preferredLabel_y'].agg(list)\n",
        "    .rename(columns={'preferredLabel_y': 'expected_esco_skills'})\n",
        ")\n",
        "\n",
        "expected_skills.to_csv('expected_esco_skills.csv', index=False)\n",
        "pd.read_csv(\"expected_esco_skills.csv\").head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJUV-J5K091m"
      },
      "source": [
        "### Merge Expected ESCO Skills for LLM Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pNTVCyK8rW5"
      },
      "outputs": [],
      "source": [
        "df_map = pd.read_csv(\"mapped_skills_output.csv\")\n",
        "df_exp = pd.read_csv(\"expected_esco_skills.csv\")\n",
        "\n",
        "# Clean the category names for consistent merging\n",
        "df_map['Category'] = df_map['Category'].str.lower().str.strip()\n",
        "df_exp['category'] = df_exp['category'].str.lower().str.strip()\n",
        "\n",
        "# Get the expected ESCO skills for Data Scientist\n",
        "data_scientist_skills = df_exp[df_exp['category'] == 'data scientist']['expected_esco_skills'].iloc[0]\n",
        "\n",
        "# Add expected skills column to all Data Science rows\n",
        "df_map['expected_esco_skills'] = df_map['Category'].apply(\n",
        "    lambda x: data_scientist_skills if x == 'data science' else None\n",
        ")\n",
        "\n",
        "# Reorder columns for better readability\n",
        "final_df = df_map[['Category', 'expected_esco_skills', 'extracted_skills_raw',\n",
        "                'original_extracted_skills_for_eval', 'mapped_skills_str']]\n",
        "\n",
        "print(final_df.head().to_markdown(index=False))\n",
        "final_df.to_csv(\"mapped_skills_with_expected_esco_for_ds.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ91iEr81L9g"
      },
      "source": [
        "### Performance Evaluation LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRXhQdGDGZwy"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"mapped_skills_with_expected_esco_for_ds.csv\")\n",
        "\n",
        "def parse_skills(skills_str):\n",
        "    \"\"\"Convert skill string to standardized set of skills.\"\"\"\n",
        "    if pd.isna(skills_str) or not str(skills_str).strip():\n",
        "        return set()\n",
        "    try:\n",
        "        return {str(s).lower().strip() for s in ast.literal_eval(skills_str)}\n",
        "    except (ValueError, SyntaxError):\n",
        "        return {s.strip().lower() for s in str(skills_str).split(',') if s.strip()}\n",
        "\n",
        "# Process skill columns\n",
        "df['expected_skills'] = df['expected_esco_skills'].apply(parse_skills)\n",
        "df['mapped_skills'] = df['mapped_skills_str'].apply(parse_skills)\n",
        "\n",
        "def calculate_metrics(gt_set, pred_set):\n",
        "    \"\"\"Calculate precision, recall, and F1-score between skill sets.\"\"\"\n",
        "    tp = len(pred_set & gt_set)\n",
        "    fp = len(pred_set - gt_set)\n",
        "    fn = len(gt_set - pred_set)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Filter and calculate metrics for Data Scientist\n",
        "ce_df = df[df['Category'].str.lower() == 'data science'].copy()\n",
        "\n",
        "if ce_df.empty:\n",
        "    print(\"No Data Scientist records found with expected skills.\")\n",
        "else:\n",
        "    # Calculate metrics\n",
        "    ce_df[['precision', 'recall', 'f1_score']] = ce_df.apply(\n",
        "        lambda r: calculate_metrics(r['expected_skills'], r['mapped_skills']),\n",
        "        axis=1, result_type='expand'\n",
        "    )\n",
        "\n",
        "    # Add intersection skills\n",
        "    ce_df['intersection_skills'] = ce_df.apply(\n",
        "        lambda r: list(r['mapped_skills'] & r['expected_skills']), axis=1\n",
        "    )\n",
        "\n",
        "    display_cols = ['Category', 'intersection_skills','precision',\n",
        "                    'recall', 'f1_score', 'mapped_skills_str','expected_esco_skills']\n",
        "    print(ce_df[display_cols].head(10).to_markdown(index=False))\n",
        "    print(f\"\\nAverage Precision: {ce_df['precision'].mean():.4f}\")\n",
        "    print(f\"Average Recall:    {ce_df['recall'].mean():.4f}\")\n",
        "    print(f\"Average F1-Score:  {ce_df['f1_score'].mean():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRgzqAOVTZlq"
      },
      "source": [
        "### Cleaning and Extracting ( LLM +KG )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyxO3zqNl_vp"
      },
      "outputs": [],
      "source": [
        "df_resumes_for_extraction = pd.read_csv(\"resumeAtlas_cleaned.csv\")\n",
        "df_resumes_for_extraction = df_resumes_for_extraction[df_resumes_for_extraction['Category'] == 'Data Science'].copy()\n",
        "RESUME_TEXT_COLUMN = \"Text_Clean\"\n",
        "\n",
        "# Load ESCO data for Domain-Specific Skills\n",
        "esco_df_full = pd.read_csv(\"skills_en.csv\")\n",
        "\n",
        "# Data Science Keywords\n",
        "data_science_keywords = [\n",
        "    \"Python\", \"R\", \"SQL\", \"PySpark\", \"Scala\", \"Julia\",\n",
        "    \"Jupyter Notebook\", \"Google Colab\", \"RStudio\",\n",
        "    \"Pandas\", \"NumPy\", \"Polars\", \"Dask\", \"Apache Arrow\",\n",
        "    \"PyArrow\", \"SQLAlchemy\", \"psycopg2\",\n",
        "    \"Scikit-learn\", \"TensorFlow\", \"PyTorch\", \"Keras\", \"XGBoost\",\n",
        "    \"LightGBM\", \"CatBoost\", \"Hugging Face\", \"spaCy\", \"NLTK\",\n",
        "    \"Apache Spark\", \"Hadoop\", \"Databricks\", \"Snowflake\",\n",
        "    \"AWS SageMaker\", \"Azure ML\", \"GCP Vertex AI\", \"BigQuery\",\n",
        "    \"Redshift\", \"Delta Lake\", \"Apache Kafka\",\n",
        "    \"Matplotlib\", \"Seaborn\", \"Plotly\", \"Dash\", \"Streamlit\",\n",
        "    \"Tableau\", \"Power BI\", \"Looker\", \"Metabase\",\n",
        "    \"MLflow\", \"Kubeflow\", \"Airflow\", \"Prefect\", \"Docker\",\n",
        "    \"Kubernetes\", \"FastAPI\", \"Flask\", \"TF Serving\",\n",
        "    \"Deep Learning\", \"Computer Vision\", \"NLP\", \"LLMs\",\n",
        "    \"Time Series Analysis\", \"Survival Analysis\", \"Reinforcement Learning\",\n",
        "    \"Generative AI\", \"Graph Neural Networks\",\n",
        "    \"ETL\", \"ELT\", \"Data Pipelines\", \"Data Warehousing\",\n",
        "    \"Data Modeling\", \"dbt\", \"Airbyte\", \"Fivetran\",\n",
        "    \"Statistical Modeling\", \"Bayesian Statistics\", \"Experimental Design\",\n",
        "    \"Causal Inference\", \"Optimization\", \"Linear Algebra\",\n",
        "    \"Fraud Detection\", \"Recommendation Systems\", \"Forecasting\",\n",
        "    \"Anomaly Detection\", \"Customer Segmentation\", \"A/B Testing\"\n",
        "]\n",
        "pattern = '|'.join([re.escape(k) for k in data_science_keywords])\n",
        "\n",
        "# Filter and Sample ESCO skills\n",
        "esco_df_ce_related = esco_df_full[\n",
        "    esco_df_full['preferredLabel'].str.contains(pattern, case=False, na=False, regex=True) |\n",
        "    esco_df_full['altLabels'].astype(str).str.contains(pattern, case=False, na=False, regex=True)\n",
        "].copy()\n",
        "\n",
        "n_samples_for_prompt = 50\n",
        "num_available = len(esco_df_ce_related)\n",
        "if num_available == 0:\n",
        "    print(\"WARNING: No Data Scientist related ESCO skills found. ESCO sample will be empty.\")\n",
        "    esco_sample_skills = []\n",
        "else:\n",
        "    num_to_sample = min(n_samples_for_prompt, num_available)\n",
        "    if num_to_sample < n_samples_for_prompt:\n",
        "        print(f\"WARNING: Filtered CE skills ({num_available}) < desired ({n_samples_for_prompt}). Sampling {num_to_sample}.\")\n",
        "    esco_sample_skills = esco_df_ce_related['preferredLabel'].sample(n=num_to_sample, random_state=42).tolist()\n",
        "\n",
        "esco_skills_string = \", \".join(esco_sample_skills)\n",
        "\n",
        "#  Few-Shot Examples\n",
        "few_shot_examples_ds = f\"\"\"\n",
        "Example 1:\n",
        "Resume: \\\"\\\"\\\"\n",
        "Senior Data Scientist - Machine Learning Specialist\n",
        "Experience:\n",
        "- Developed production ML models for customer churn prediction using XGBoost and PyTorch\n",
        "- Implemented end-to-end MLOps pipelines with MLflow and AWS SageMaker\n",
        "- Designed A/B testing frameworks to evaluate model performance in production\n",
        "- Optimized NLP pipelines for text classification using Hugging Face transformers\n",
        "\\\"\\\"\\\"\n",
        "Skills: Machine Learning, XGBoost, PyTorch, MLOps, MLflow, AWS SageMaker, A/B Testing, NLP, Hugging Face\n",
        "\n",
        "Example 2:\n",
        "Resume: \\\"\\\"\\\"\n",
        "Data Engineer - Cloud Infrastructure\n",
        "Experience:\n",
        "- Built real-time data pipelines using Apache Spark and Kafka on Azure Databricks\n",
        "- Implemented dimensional data models in Snowflake for analytics\n",
        "- Automated ETL processes with Airflow and dbt\n",
        "- Developed CI/CD pipelines for data applications using Docker and Kubernetes\n",
        "\\\"\\\"\\\"\n",
        "Skills: Data Engineering, Apache Spark, Kafka, Azure Databricks, Snowflake, ETL, Airflow, dbt, Docker, Kubernetes\n",
        "\n",
        "Example 3:\n",
        "Resume: \\\"\\\"\\\"\n",
        "Analytics Manager - Business Intelligence\n",
        "Experience:\n",
        "- Led team developing interactive dashboards in Tableau and Power BI\n",
        "- Established company-wide metrics framework for executive reporting\n",
        "- Conducted pricing elasticity analysis using Bayesian statistical models\n",
        "- Mentored junior analysts in SQL and Python for data analysis\n",
        "\\\"\\\"\\\"\n",
        "Skills: Business Intelligence, Tableau, Power BI, Data Visualization, SQL, Python, Bayesian Statistics, Leadership\n",
        "\"\"\"\n",
        "\n",
        "#  Skill Extraction Function for LLM+KG\n",
        "LLAMA_MODEL_ID = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
        "\n",
        "def extract_skills_llama3_sambanova_kg(resume_text, esco_context_skills_str, few_shot_examples_str, client):\n",
        "    MAX_RESUME_CHARS_FOR_LLM = 4000\n",
        "    resume_text_for_llm = resume_text[:MAX_RESUME_CHARS_FOR_LLM] + \"...\" if len(resume_text) > MAX_RESUME_CHARS_FOR_LLM else resume_text\n",
        "\n",
        "    system_prompt_kg = (\n",
        "        \"You are a professional resume parser. \"\n",
        "        \"Extract all technical skills from the resume below. \"\n",
        "        \"Only output a clean, comma-separated list. No extra words or introductory phrases.\"\n",
        "        f\"\\n\\n{few_shot_examples_str}\\n\\n\"\n",
        "        \"For guidance and inspiration, consider skills that are closely related to or are present in the following list of relevant ESCO skills::\"\n",
        "        f\"[{esco_context_skills_str}].\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt_kg},\n",
        "        {\"role\": \"user\", \"content\": f\"Resume: \\\"{resume_text_for_llm}\\\"\\n\\nSkills:\"}\n",
        "    ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=LLAMA_MODEL_ID,\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "        max_tokens=200,\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "df_resumes_for_extraction[\"extracted_skills_raw_kg\"] = df_resumes_for_extraction[RESUME_TEXT_COLUMN].progress_apply(\n",
        "    lambda x: extract_skills_llama3_sambanova_kg(x, esco_skills_string, few_shot_examples_ds, client)\n",
        ")\n",
        "\n",
        "output_path_kg = \"extracted_skills_kg_output.csv\"\n",
        "df_resumes_for_extraction.to_csv(output_path_kg, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhoPTCEW0h1q"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"extracted_skills_kg_output.csv\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR6Pr8j0TtHL"
      },
      "source": [
        "### Mapping skills to ESCO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmbTKyeWqdtK"
      },
      "outputs": [],
      "source": [
        "df_mapping = pd.read_csv(\"extracted_skills_kg_output.csv\")\n",
        "esco_df = pd.read_csv(\"skills_en.csv\")[['preferredLabel', 'altLabels']].copy()\n",
        "\n",
        "# Clean LLM Output Function\n",
        "def clean_extracted_skills(text):\n",
        "    \"\"\"Cleans raw LLM text output into a set of normalized skill phrases.\"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return set()\n",
        "\n",
        "    text = text.lower().replace(';', ',').replace(' and ', ', ')\n",
        "    raw_skill_candidates = re.split(r',\\s*|\\s*,\\s*', text)\n",
        "\n",
        "    return {\n",
        "        re.sub(r'[^a-z0-9\\s\\.\\+#-]+', '', s).strip()\n",
        "        for s in raw_skill_candidates\n",
        "        if s.strip() and len(s.strip()) > 1 and not s.strip().isdigit()\n",
        "    }\n",
        "\n",
        "# Apply cleaning\n",
        "df_mapping['extracted_skills_set'] = df_mapping['extracted_skills_raw_kg'].apply(clean_extracted_skills)\n",
        "\n",
        "# Pre-process ESCO data for faster lookups\n",
        "esco_preferred_lower_list = esco_df['preferredLabel'].str.lower().tolist()\n",
        "pref_map = {label.lower(): label for label in esco_df['preferredLabel'].unique()}\n",
        "\n",
        "alt_map = {\n",
        "    alt.strip(): row['preferredLabel']\n",
        "    for _, row in esco_df.iterrows()\n",
        "    if isinstance(row['altLabels'], str)\n",
        "    for alt in row['altLabels'].lower().replace('\"', '').split('|')\n",
        "    if alt.strip()\n",
        "}\n",
        "\n",
        "# ESCO Mapping Function\n",
        "def map_to_esco(skill_name, pref_map_ref, alt_map_ref, esco_lower_list_ref):\n",
        "    \"\"\"Maps an extracted skill to an ESCO preferredLabel using exact/fuzzy matching.\"\"\"\n",
        "    skill = str(skill_name).lower().strip()\n",
        "    if not skill:\n",
        "        return None\n",
        "\n",
        "    # Exact match (preferred or alternative)\n",
        "    if skill in pref_map_ref: return pref_map_ref[skill]\n",
        "    if skill in alt_map_ref: return alt_map_ref[skill]\n",
        "\n",
        "    # Fuzzy match\n",
        "    fuzzy_match_result = process.extractOne(skill, esco_lower_list_ref, scorer=fuzz.token_set_ratio)\n",
        "    if fuzzy_match_result and fuzzy_match_result[1] >= 60: # score >= 60\n",
        "        # Retrieve original preferredLabel case\n",
        "        original_label_row = esco_df[esco_df['preferredLabel'].str.lower() == fuzzy_match_result[0]]\n",
        "        if not original_label_row.empty:\n",
        "            return original_label_row['preferredLabel'].iloc[0]\n",
        "    return None\n",
        "\n",
        "# Apply ESCO Mapping\n",
        "df_mapping[\"mapped_skills_str\"] = df_mapping['extracted_skills_set'].progress_apply(\n",
        "    lambda s: \", \".join(sorted(list(filter(None, [map_to_esco(x, pref_map, alt_map, esco_preferred_lower_list) for x in s]))))\n",
        ")\n",
        "\n",
        "output_path = \"mapped_skills_kg_output.csv\"\n",
        "\n",
        "columns_to_save_kg = [\n",
        "    'Unnamed: 0', 'Category', 'Text_Clean', 'extracted_skills_raw_kg',\n",
        "    'original_extracted_skills_for_eval_kg', 'mapped_skills_str'\n",
        "]\n",
        "\n",
        "df_mapping['original_extracted_skills_for_eval_kg'] = df_mapping['extracted_skills_set'].apply(lambda s: str(list(s)))\n",
        "\n",
        "existing_columns_to_save_kg = [col for col in columns_to_save_kg if col in df_mapping.columns]\n",
        "df_mapping[existing_columns_to_save_kg].to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Mapped skills saved to {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4THs6p_4INE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"mapped_skills_kg_output.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txI23uHM0zS-"
      },
      "source": [
        "### Merge Expected ESCO Skills for LLM+KG Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCBV3CLN8IWz"
      },
      "outputs": [],
      "source": [
        "df_map = pd.read_csv(\"mapped_skills_kg_output.csv\")\n",
        "df_exp = pd.read_csv(\"expected_esco_skills.csv\")\n",
        "\n",
        "#  Clean the category names for consistent merging\n",
        "df_map['Category'] = df_map['Category'].str.lower().str.strip()\n",
        "df_exp['category'] = df_exp['category'].str.lower().str.strip()\n",
        "\n",
        "#  Get the expected ESCO skills for Data Scientist\n",
        "data_scientist_skills = df_exp[df_exp['category'] == 'data scientist']['expected_esco_skills'].iloc[0]\n",
        "\n",
        "#  Add expected skills column to all Data Science rows\n",
        "df_map['expected_esco_skills'] = df_map['Category'].apply(\n",
        "    lambda x: data_scientist_skills if x == 'data science' else None\n",
        ")\n",
        "\n",
        "# Reorder columns for better readability\n",
        "final_df = df_map[['Category','expected_esco_skills','extracted_skills_raw_kg',\n",
        "                'original_extracted_skills_for_eval_kg', 'mapped_skills_str']]\n",
        "\n",
        "print(final_df.head().to_markdown(index=False))\n",
        "final_df.to_csv(\"mapped_skills_kg_with_expected_esco_for_ds.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjeezKTd0K8u"
      },
      "source": [
        "### Performance Evaluation LLM+KG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsBThH0Mw5ck"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"mapped_skills_kg_with_expected_esco_for_ds.csv\")\n",
        "\n",
        "def parse_skills(skills_str):\n",
        "    \"\"\"Convert skill string to standardized set of skills.\"\"\"\n",
        "    if pd.isna(skills_str) or not str(skills_str).strip():\n",
        "        return set()\n",
        "    try:\n",
        "\n",
        "        return {str(s).lower().strip() for s in ast.literal_eval(skills_str)}\n",
        "    except (ValueError, SyntaxError):\n",
        "\n",
        "        return {s.strip().lower() for s in str(skills_str).split(',') if s.strip()}\n",
        "\n",
        "# Process skill columns\n",
        "df['expected_skills'] = df['expected_esco_skills'].apply(parse_skills)\n",
        "df['mapped_skills'] = df['mapped_skills_str'].apply(parse_skills)\n",
        "\n",
        "def calculate_metrics(gt_set, pred_set):\n",
        "    \"\"\"Calculate precision, recall, and F1-score between skill sets.\"\"\"\n",
        "    tp = len(pred_set & gt_set)\n",
        "    fp = len(pred_set - gt_set)\n",
        "    fn = len(gt_set - pred_set)\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "# Filter and calculate metrics for Data Scientist\n",
        "ce_df = df[df['Category'].str.lower() == 'data science'].copy()\n",
        "\n",
        "if ce_df.empty:\n",
        "    print(\"No Data Scientist records found with expected skills for LLM+KG evaluation.\")\n",
        "else:\n",
        "    # Calculate metrics\n",
        "    ce_df[['precision', 'recall', 'f1_score']] = ce_df.apply(\n",
        "        lambda r: calculate_metrics(r['expected_skills'], r['mapped_skills']),\n",
        "        axis=1, result_type='expand'\n",
        "    )\n",
        "\n",
        "    # Add intersection skills\n",
        "    ce_df['intersection_skills'] = ce_df.apply(\n",
        "        lambda r: list(r['mapped_skills'] & r['expected_skills']), axis=1\n",
        "    )\n",
        "\n",
        "    display_cols = ['Category', 'intersection_skills', 'precision',\n",
        "                    'recall', 'f1_score', 'mapped_skills_str', 'expected_esco_skills']\n",
        "    print(\"\\n--- LLM+KG Model Performance on Civil Engineer Skills ---\")\n",
        "    print(ce_df[display_cols].head(10).to_markdown(index=False))\n",
        "    print(f\"\\nAverage Precision: {ce_df['precision'].mean():.4f}\")\n",
        "    print(f\"Average Recall:    {ce_df['recall'].mean():.4f}\")\n",
        "    print(f\"Average F1-Score:  {ce_df['f1_score'].mean():.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}